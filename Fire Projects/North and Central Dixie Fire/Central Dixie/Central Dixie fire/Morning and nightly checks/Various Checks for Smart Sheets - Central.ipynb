{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6df511",
   "metadata": {},
   "source": [
    "# What databases need to be downloaded:\n",
    "* smartsheets - API is running no need\n",
    "* RTR - aDataManagerTicketExport \n",
    "* RTR URL: https://rtr.tdr.tetratech.com/rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f992a",
   "metadata": {},
   "source": [
    "# # What we are checking over view:\n",
    "\n",
    "#### Multiple checks\n",
    "* Soil data with share ppoint and Smart sheet comparasions(learning curve to read the out put)\n",
    "* Soil- Location in smart sheets\n",
    "* Soil -Sample date after recived from lab dates\n",
    "* Soil -Sample approval but debris status still in soils\n",
    "#### other checks\n",
    "* Soil sample prio to debris finish\n",
    "* ROE checks - ROE date is blank | ROE Verified is blank | Property Type is blank\n",
    "* FSO checks - FSO sent to county is not blank with ROE type full program and FSO debris complete is blank\n",
    "* ASB sample sent prior to ASB assessment\n",
    "* ASB results prior to ASB sample sent date\n",
    "* Debris start date is after debris finish date\n",
    "* Missing lat and long\n",
    "* Tree check - Checks for number of days from tree felling complete till ready for TISW\n",
    "* Salmon - obsolete\n",
    "* 811 A&M checks\n",
    "* Bird nests\n",
    "* Bridge CRossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7f5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import smartsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f92f39",
   "metadata": {},
   "source": [
    "Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79e737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileType_ex = \".xlsx\"\n",
    "fileType_csv = \".csv\"\n",
    "division = 'Northern Division' # will be opposite of the division we are checking. Help check for evrything NOT in Northern Division\n",
    "division_rtr = 'NORTHERN DIVISION'\n",
    "# grabs smartsheet data \n",
    "# central = r\"C:\\Users\\jacque.trahan\\Downloads\\Central Division 2021 Debris Removal Tracker*\" \n",
    "# south = r\"C:\\Users\\jacque.trahan\\Downloads\\South Central Division 2021 Debris Removal Tracker*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112dcaae",
   "metadata": {},
   "source": [
    "# Load in smartsheet using the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cc6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smartsheets Shet IDs\n",
    "Central_id = '1844440261257092'\n",
    "South_id= '6292262490531716'\n",
    "\n",
    "# Smart sheet APIs\n",
    "# Central's API\n",
    "Central = smartsheet.Smartsheet('6jJFxnAfFsDErU0BSr1Ae4D6cHq0zenczVR12') #API\n",
    "Central.errors_as_exceptions(True)# Make sure we don't miss any errors\n",
    "\n",
    "# Central's API\n",
    "South = smartsheet.Smartsheet(\"H8mqAo60J2zGHSrJEwmlMoY88A9yjgCo6RnSI\") # API\n",
    "South.errors_as_exceptions(True)# Make sure we don't miss any errors\n",
    "\n",
    "# load in Smartsheets to pandas data frame - A FUNCTION IS NEEDED\n",
    "# Function to read in column titles and row vales and make out data frames\n",
    "def smartsheet_loadup(sheet):\n",
    "    \"\"\"Runs through the smartsheets collection of values and create a Pandas data frame\"\"\"\n",
    "    columns = [col.title for col in sheet.columns]\n",
    "    rows = []\n",
    "    for row in sheet.rows:\n",
    "        cells = []\n",
    "        for cell in row.cells:\n",
    "            cells.append(cell.value)\n",
    "        rows.append(cells)\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    return df\n",
    "\n",
    "Central_SS = smartsheet_loadup(Central.Sheets.get_sheet(Central_id))\n",
    "South_SS = smartsheet_loadup(South.Sheets.get_sheet(South_id))\n",
    "\n",
    "df_both = pd.concat([Central_SS,South_SS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc338303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_both.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d9815",
   "metadata": {},
   "source": [
    "# Smart Sheets dowload upload from download folder and concate\n",
    "\n",
    "### made better above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487d7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Central\n",
    "# load = glob.glob(central+fileType_ex)\n",
    "# df = pd.read_excel(max(load, key=os.path.getctime), parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79357369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # South Central\n",
    "# load2 = glob.glob(south+fileType_ex)\n",
    "# df2 = pd.read_excel(max(load2, key=os.path.getctime), parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef43d18",
   "metadata": {},
   "source": [
    "#### Concate Central and South Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48a65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_both = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4270a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_both.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3454a",
   "metadata": {},
   "source": [
    "# Fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad95ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(df, comp1=None, comp2=None, comp3=None):\n",
    "    \"\"\"Compares columns in our dataframe\"\"\"\n",
    "    if comp3 == None:\n",
    "        if df[comp1] == df[comp2]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if df[comp1] == df[comp2] and df[comp2] == df[comp3]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "        \n",
    "        \n",
    "def greater(df, comp1=None, comp2=None):\n",
    "    \"\"\"Checks for dates greater than another\"\"\"\n",
    "    if df[comp1] > df[comp2]:\n",
    "        return \"Greater than\"\n",
    "    else:\n",
    "        return \"Less Than\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b547b79",
   "metadata": {},
   "source": [
    "# Soil Share Point Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "309c5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_soilTracker = r\"C:\\Users\\jacque.trahan\\Downloads\\Soil Sampling Tracker*\"\n",
    "load_soil = glob.glob(path_soilTracker + fileType_csv)\n",
    "soils_sharePoint = pd.read_csv(max(load_soil, key=os.path.getctime), usecols=['APN', 'APN Status', 'Field Notes', 'Tt Recommendation', \n",
    "                                                                       'State Recommendation', 'State Rec Details',\n",
    "                                                                       'Access Issue', 'DTSC Mercury Site','State Recommendation',\n",
    "                                                                      'State Rec Details','State Rec Date','QC State Recs','ExpectedResultsDate',\n",
    "                                                                      'Current Sample Event','Division', 'Recs Notes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b922f",
   "metadata": {},
   "source": [
    "# RTR data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "423627da",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\jacque.trahan\\Downloads\\aDataManagerTicketExport*\"\n",
    "load_rtr = glob.glob(path+fileType_ex)\n",
    "df_RTR = pd.read_excel(max(load_rtr, key=os.path.getctime))\n",
    "\n",
    "df_RTR['Zone Name'] = df_RTR['Zone Name'].str[:3] + \"-\" + df_RTR['Zone Name'].str[3:6] + \"-\" + df_RTR['Zone Name'].str[6:]\n",
    "df_RTR['Zone Name'] = df_RTR['Zone Name'].str.replace('167-310-2500', '167-310-25-00')\n",
    "df_RTR['Service Code'] = df_RTR['Service Code'].str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16ebca",
   "metadata": {},
   "source": [
    "# Check ROE dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a1f317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROE_dates = df_both[['APN_ROW Segment','Street #', 'Street Name', 'County','Debris Crew', 'Structural Status',\n",
    "                         'ROE Date', 'ROE Verified',\n",
    "                    'Property Type', ]]\n",
    "ROE_dates = ROE_dates[(ROE_dates['ROE Date'].isnull()) | \n",
    "                     (ROE_dates['ROE Verified'].isnull()) | \n",
    "                    (ROE_dates['Property Type'].isnull())]\n",
    "\n",
    "ROE_dates.set_index('APN_ROW Segment', inplace=True)\n",
    "ROE_dates.to_excel('ROE Random Checks.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f928d2f",
   "metadata": {},
   "source": [
    "# FSO Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "815d1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FSO = df_both.copy()\n",
    "\n",
    "FSO = FSO[(~FSO['FSO Sent to County'].isnull()) & (FSO['ROE Type'] == \"Full Program ROE (debris + trees)\") &\n",
    "          (FSO['Debris FSO Complete'].isnull())]\n",
    "\n",
    "FSO = FSO[['APN_ROW Segment','Street #', 'Street Name', 'County', 'Structural Status','ROE Type',\n",
    "           'Erosion Control Complete', 'Erosion Control Waiver',\n",
    "          'Debris FSO Complete', 'FSO Complete', 'FSO Sent to County']]\n",
    "\n",
    "FSO.set_index('APN_ROW Segment', inplace=True)\n",
    "FSO.to_excel('FSO Check.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e596e0b",
   "metadata": {},
   "source": [
    "# ASB sample sent prior to ASB assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e892c5e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asb_sample = df_both.copy()\n",
    "asb_sample = asb_sample[['APN_ROW Segment','Street #', 'Street Name', 'County',\n",
    "                         'ASB Assessment', 'ASB Sample Sent']]\n",
    "asb_sample = asb_sample[(asb_sample['ASB Assessment'] > asb_sample['ASB Sample Sent'])]\n",
    "\n",
    "asb_sample.set_index('APN_ROW Segment', inplace=True)\n",
    "asb_sample.to_excel('ASB sample sent prior to ASB assessment.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52b963",
   "metadata": {},
   "source": [
    "# ASB results prior to ASB sample sent date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc6b7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "asb_res = df_both.copy()\n",
    "asb_res = asb_res[['APN_ROW Segment','Street #', 'Street Name', 'County',\n",
    "                   'ASB Sample Sent','ASB Results Received', 'ASB Results']]\n",
    "asb_res = asb_res[(asb_res['ASB Sample Sent'].isna()) & (asb_res['ASB Results'].notna())]\n",
    "\n",
    "asb_res.set_index('APN_ROW Segment', inplace=True)\n",
    "asb_res.to_excel('ASB results prior to ASB sample sent date.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8f322",
   "metadata": {},
   "source": [
    "# Debris start after to debris finish\n",
    "### Check Debris dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af88c994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_both['Debris Finish'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f47c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Debris_dates = df_both.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18dc99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Debris_dates = df_both.copy()\n",
    "Debris_dates = Debris_dates[['APN_ROW Segment','Street #', 'Street Name', 'County',\n",
    "                          'Debris Start', 'Debris Finish', 'State Rep Sign-Off for DR']]\n",
    "\n",
    "Debris_dates['Debris Start'] = pd.to_datetime(Debris_dates['Debris Start'])\n",
    "Debris_dates['Debris Finish'] = pd.to_datetime(Debris_dates['Debris Finish'])\n",
    "\n",
    "Debris_dates.insert(Debris_dates.columns.get_loc('State Rep Sign-Off for DR')+1, \"Finish start before Debris end\",\n",
    "                   Debris_dates.apply(greater,comp1='Debris Start', comp2='Debris Finish', axis=1))\n",
    "Debris_dates.set_index('APN_ROW Segment', inplace=True)\n",
    "Debris_dates.to_excel('Check debris start finish and state sign off dates.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f8621",
   "metadata": {},
   "source": [
    "# Soil Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f2c89",
   "metadata": {},
   "source": [
    "## Soil sample prior to debris finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1084d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_debris = df_both.copy()\n",
    "soil_debris = soil_debris[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status',\n",
    "                           'Soil Sample', 'Debris Finish']]\n",
    "\n",
    "soil_debris = soil_debris[(soil_debris['Soil Sample'] < soil_debris['Debris Finish'])]\n",
    "\n",
    "soil_debris.set_index('APN_ROW Segment', inplace=True)\n",
    "soil_debris.to_excel(\"Soil prior to debris Finish.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5467c4",
   "metadata": {},
   "source": [
    "## Multiple checks\n",
    "* Location in smart sheets\n",
    "* Sample date after recived from lab dates\n",
    "* Sample approval but debris status still in soils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "855caacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "soilTak_soilRec = df_both.copy()\n",
    "soilTak_soilRec = soilTak_soilRec[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status','Debris Crew',\n",
    "                                   'Soil Sample', 'Soil Sample Results Rec\\'d from Lab',\"Soil Sample Results\",\n",
    "                                  'Soil Boring','Soil Boring Results Rec\\'d from Lab', 'Soil Boring Results',\n",
    "                                  'Soil Re-scrape',\"Re-scrape Results Rec'd from Lab\", \"Re-scrape Results\",\n",
    "                                  'Soil Re-scrape 2',\"Re-scrape 2 Results Rec'd from Lab\", \"Re-scrape 2 Results\",\n",
    "                                  'Soil Rescrape 3',\"Re-scrape 3 Results Rec'd from Lab\", 'Re-scrape 3 Results',\n",
    "                                  \"Soil Samples Approved\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3f9d98",
   "metadata": {},
   "source": [
    "#### See where we are in Smartsheet with soils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c554886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soil_location(df):\n",
    "    \"\"\"Prints out column header if the cell is not blank\"\"\"\n",
    "    if pd.notna(df[\"Soil Samples Approved\"]):\n",
    "        return \"Soil Samples Approved\"\n",
    "    \n",
    "    elif pd.notnull(df['Re-scrape 3 Results']):\n",
    "        return 'Re-scrape 3 Results'\n",
    "    \n",
    "    elif pd.notnull(df[\"Re-scrape 3 Results Rec'd from Lab\"]):\n",
    "        return \"Re-scrape 3 Results Rec'd from Lab\"\n",
    "    \n",
    "    elif pd.notnull(df[\"Re-scrape 2 Results\"]):\n",
    "        return \"Re-scrape 2 Results\"\n",
    "    \n",
    "    elif pd.notnull(df[\"Re-scrape 2 Results Rec'd from Lab\"]):\n",
    "        return \"Re-scrape 2 Results Rec'd from Lab\"\n",
    "    \n",
    "    elif pd.notnull(df['Soil Re-scrape 2']):\n",
    "        return 'Soil Re-scrape 2'\n",
    "    \n",
    "    elif pd.notnull(df[\"Re-scrape Results\"]):\n",
    "        return \"Re-scrape Results\"\n",
    "    \n",
    "    elif pd.notnull(df[\"Re-scrape Results Rec'd from Lab\"]):\n",
    "        return \"Re-scrape Results Rec'd from Lab\"\n",
    "    \n",
    "    elif pd.notnull(df['Soil Re-scrape']):\n",
    "        return 'Soil Re-scrape'\n",
    "    \n",
    "    elif pd.notnull(df['Soil Boring Results']):\n",
    "        return 'Soil Boring Results'\n",
    "    \n",
    "    elif pd.notnull(df['Soil Boring Results Rec\\'d from Lab']):\n",
    "        return 'Soil Boring Results Rec\\'d from Lab'\n",
    "    \n",
    "    elif pd.notnull(df['Soil Boring']):\n",
    "        return 'Soil Boring'\n",
    "    \n",
    "    elif pd.notnull(df[\"Soil Sample Results\"]):\n",
    "        return \"Soil Sample Results\"\n",
    "    \n",
    "    elif pd.notnull(df['Soil Sample Results Rec\\'d from Lab']):\n",
    "        return 'Soil Sample Results Rec\\'d from Lab'\n",
    "    \n",
    "    elif pd.notnull(df['Soil Sample']):\n",
    "        return 'Soil Sample'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "865a29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soilTak_soilRec.insert(soilTak_soilRec.columns.get_loc(\"Soil Samples Approved\")+1, \"Location in smartsheets\",\n",
    "                      soilTak_soilRec.apply(soil_location, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b71c7",
   "metadata": {},
   "source": [
    "### Merge with the Soil Share point with the following columns\n",
    "* APN\n",
    "* Field Notes\n",
    "* Tt Recommendation\n",
    "* State Recommendation\n",
    "* State Rec Details\n",
    "* Access Issue\n",
    "* DTSC Mercury Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cfebe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "soils_sharePoint = soils_sharePoint[~(soils_sharePoint['Division'].isin([division]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "404776e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soil_final = soilTak_soilRec.merge(soils_sharePoint,\n",
    "                              how='outer',\n",
    "                              left_on='APN_ROW Segment',\n",
    "                              right_on='APN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a2f97",
   "metadata": {},
   "source": [
    "### Check for date discrepancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd3668de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Soil_Sample(df):\n",
    "    if df['Soil Sample'] > df['Soil Sample Results Rec\\'d from Lab']:\n",
    "        return 'Check Soil Sample Dates'\n",
    "    else:\n",
    "        return 'Match'\n",
    "    \n",
    "def Soil_Boring(df):\n",
    "    if df['Soil Boring'] > df['Soil Boring Results Rec\\'d from Lab']:\n",
    "        return 'Check Soil Boring Dates'\n",
    "    else:\n",
    "        return 'Match'\n",
    "    \n",
    "def Soil_Rescrape(df):\n",
    "    if df['Soil Re-scrape'] > df[\"Re-scrape Results Rec'd from Lab\"]:\n",
    "        return 'Check Soil Re-scrape Dates'\n",
    "    else:\n",
    "        return 'Match'\n",
    "def Soil_Rescrape2(df):    \n",
    "    if df['Soil Re-scrape 2'] > df[\"Re-scrape 2 Results Rec'd from Lab\"]:\n",
    "        return 'Check Soil Re-scrape 2 Dates'\n",
    "    else:\n",
    "        return 'Match'\n",
    "\n",
    "def Soil_Rescrape3(df):    \n",
    "    if df['Soil Rescrape 3'] > df[\"Re-scrape 3 Results Rec'd from Lab\"]:\n",
    "        return 'Check Soil Rescrape 3 Dates'\n",
    "    else:\n",
    "        return 'Match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4ef4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soil_final = Soil_final.copy()\n",
    "Soil_final = Soil_final[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status','Debris Crew',\n",
    "                         \"Location in smartsheets\", 'APN Status',\n",
    "                         'Soil Sample', 'Soil Sample Results Rec\\'d from Lab',\"Soil Sample Results\",\n",
    "                         'Recs Notes','Current Sample Event','ExpectedResultsDate',\"Soil Samples Approved\",\n",
    "                         \n",
    "                      'Soil Boring','Soil Boring Results Rec\\'d from Lab', 'Soil Boring Results',\n",
    "                         \n",
    "                      'Soil Re-scrape',\"Re-scrape Results Rec'd from Lab\", \"Re-scrape Results\",\n",
    "                                             \n",
    "                      'Soil Re-scrape 2',\"Re-scrape 2 Results Rec'd from Lab\", \"Re-scrape 2 Results\",\n",
    "                                                \n",
    "                      'Soil Rescrape 3',\"Re-scrape 3 Results Rec'd from Lab\", 'Re-scrape 3 Results',\n",
    "                       \n",
    "                         \n",
    "                        'Field Notes', 'Tt Recommendation', 'State Recommendation', 'State Rec Details',\n",
    "                         'Access Issue', 'DTSC Mercury Site',\n",
    "                         'State Rec Details','State Rec Date','QC State Recs',\n",
    "                         'Division']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a27be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soil_final['Soil Sample'] = pd.to_datetime(Soil_final['Soil Re-scrape 2'])\n",
    "\n",
    "\n",
    "\n",
    "Soil_final['Soil Re-scrape 2'] = Soil_final['Soil Re-scrape 2'].fillna(pd.NaT)\n",
    "Soil_final[\"Re-scrape 2 Results Rec'd from Lab\"] = Soil_final[\"Re-scrape 2 Results Rec'd from Lab\"].fillna(pd.NaT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67100933",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soil_final['Soil Sample'] = pd.to_datetime(Soil_final['Soil Sample'])\n",
    "Soil_final['Soil Sample Results Rec\\'d from Lab'] = pd.to_datetime(Soil_final['Soil Sample Results Rec\\'d from Lab'])\n",
    "\n",
    "Soil_final['Soil Boring'] = pd.to_datetime(Soil_final['Soil Boring'])\n",
    "Soil_final['Soil Boring Results Rec\\'d from Lab'] = pd.to_datetime(Soil_final['Soil Boring Results Rec\\'d from Lab'])\n",
    "\n",
    "Soil_final['Soil Re-scrape'] = pd.to_datetime(Soil_final['Soil Re-scrape'])\n",
    "Soil_final[\"Re-scrape Results Rec'd from Lab\"] = pd.to_datetime(Soil_final[\"Re-scrape Results Rec'd from Lab\"])\n",
    "\n",
    "Soil_final['Soil Re-scrape 2'] = pd.to_datetime(Soil_final['Soil Re-scrape 2'])\n",
    "Soil_final[\"Re-scrape 2 Results Rec'd from Lab\"] = pd.to_datetime(Soil_final[\"Re-scrape 2 Results Rec'd from Lab\"])\n",
    "\n",
    "Soil_final['Soil Rescrape 3'] = pd.to_datetime(Soil_final['Soil Rescrape 3'])\n",
    "Soil_final[\"Re-scrape 3 Results Rec'd from Lab\"] = pd.to_datetime(Soil_final[\"Re-scrape 3 Results Rec'd from Lab\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b42367d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample date check\n",
    "Soil_final.insert(Soil_final.columns.get_loc(\"Soil Samples Approved\")+1, 'Soil_Sample Date checks-M',\n",
    "                 Soil_final.apply(Soil_Sample, axis=1))\n",
    "\n",
    "# Soil_Boring Check\n",
    "Soil_final.insert(Soil_final.columns.get_loc('Soil Boring Results')+1, 'Soil_Boring Date checks-M',\n",
    "                 Soil_final.apply(Soil_Boring, axis=1))\n",
    "\n",
    "#Soil_Rescrape\n",
    "Soil_final.insert(Soil_final.columns.get_loc(\"Re-scrape Results\")+1, 'Soil_Rescrape Date checks-M',\n",
    "                 Soil_final.apply(Soil_Rescrape, axis=1))\n",
    "\n",
    "#Soil_Rescrape2\n",
    "Soil_final.insert(Soil_final.columns.get_loc(\"Re-scrape 2 Results\")+1, 'Soil_Rescrape2 Date checks-M',\n",
    "                 Soil_final.apply(Soil_Rescrape2, axis=1))\n",
    "\n",
    "#Soil_Rescrape3\n",
    "Soil_final.insert(Soil_final.columns.get_loc('Re-scrape 3 Results')+1, 'Soil_Rescrape3 Date checks-M',\n",
    "                 Soil_final.apply(Soil_Rescrape3, axis=1))\n",
    "\n",
    "Soil_final.set_index('APN_ROW Segment', inplace=True)\n",
    "Soil_final.to_excel('Check Soil APN status vs structual status and current location in smartsheets.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a23d5",
   "metadata": {},
   "source": [
    "# long and lats missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e7b719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lat = df_both.copy()\n",
    "lon_lat = lon_lat[['APN_ROW Segment','Street #', 'Street Name', 'County','Latitude', 'Longitude']]\n",
    "\n",
    "lon_lat = lon_lat[lon_lat['Latitude'].isna() | lon_lat['Longitude'].isna()]\n",
    "\n",
    "lon_lat.set_index('APN_ROW Segment', inplace=True)\n",
    "lon_lat.to_excel(\"Missing long and lat.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a631c",
   "metadata": {},
   "source": [
    "# TREE CHECKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108713f",
   "metadata": {},
   "source": [
    "### import google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "716bd646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sheet ID comes right after /d/ in the URL\n",
    "Sheet_ID= '1O2dmdhEo5hJVAgRVDl4M4n3_v-KqHS56q3OZVdpZANU'\n",
    "# name of tab you want to use\n",
    "sheets_name = 'Tree RTR Tracker'\n",
    "\n",
    "# this is tricky. after /export? we must put format=csv#id={Sheet Name}   -> manually to make this work\n",
    "#gid # in URL lets you pick the sheet you want. Will need to look for that. \n",
    "url = f'https://docs.google.com/spreadsheets/d/{Sheet_ID}/export?format=csv#id={sheets_name}'\n",
    "\n",
    "google_Qc = pd.read_csv(url, header=1)\n",
    "google_Qc = google_Qc[['APN_ROW Segment', 'ECC Tree Removal Confirmation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5986cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if tree felling completed has a date and tree removal competed does not\n",
    "TREE = df_both.copy()\n",
    "TREE = TREE[(~TREE['Tree Felling Complete'].isnull()) & (TREE['Tree Removal Complete (ISW)'].isnull())]\n",
    "\n",
    "#number of days from tree removal completed\n",
    "TREE['# of days pasted Tree Felling Complete Date'] = pd.Timestamp.now().normalize()  - pd.to_datetime(TREE['Tree Felling Complete'], errors='coerce')\n",
    "\n",
    "\n",
    "#Merge smartsheets and google QC\n",
    "Tree_final = TREE.merge(google_Qc,\n",
    "                       left_on='APN_ROW Segment',\n",
    "                       right_on='APN_ROW Segment',\n",
    "                       how='left')\n",
    "\n",
    "# number of days Since notificed APN was ready for TISW\n",
    "Tree_final['# of days pasted Ready for ECC/Anvil TISW update'] = pd.Timestamp.now().normalize()  - pd.to_datetime(Tree_final['ECC Tree Removal Confirmation'], errors='coerce')\n",
    "\n",
    "Tree_final.set_index('APN_ROW Segment', inplace=True)\n",
    "Tree_final[['Street #', 'Street Name', 'Structural Status','County', 'Tree Crew',\n",
    "            'Tree Felling Complete', 'Tree Removal Complete (ISW)','ECC Tree Removal Confirmation',\n",
    "            '# of days pasted Tree Felling Complete Date','# of days pasted Ready for ECC/Anvil TISW update',\n",
    "            'Number of Trees',\n",
    "           ]].to_excel(\"Number of days TISW has been Pending.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724de5b",
   "metadata": {},
   "source": [
    "# Check Tree removal and TISW dates\n",
    "https://docs.google.com/spreadsheets/d/1wF0GLNJG0dKTnkT0fEuC-kAIU4pzrr_IyhLnJ5iEZ7s/edit#gid=1185136840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "394c1eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Planning_sheet_id = '1wF0GLNJG0dKTnkT0fEuC-kAIU4pzrr_IyhLnJ5iEZ7s'\n",
    "Planning_sheet_name = '1185136840'\n",
    "\n",
    "#gid # in URL lets you pick the sheet you want. Will need to look for that.\n",
    "url_planning = f\"https://docs.google.com/spreadsheets/d/{Planning_sheet_id}/export?gid={Planning_sheet_name}&format=csv\"\n",
    "planning_google = pd.read_csv(url_planning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcc75558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_google = planning_google.merge(df_both,\n",
    "#                                     left_on='APN_ROW Segment',\n",
    "#                                     right_on='APN_ROW Segment',\n",
    "#                                     how='left',\n",
    "#                                     suffixes=(\"_GG\",\"_SS\"))\n",
    "\n",
    "# final_google = final_google[['APN_ROW Segment', 'Tree Removal Complete_GG','Tree Removal Complete_SS']]\n",
    "# final_google['Tree Removal Complete_GG'] = pd.to_datetime(final_google['Tree Removal Complete_GG']).dt.date\n",
    "# final_google['Tree Removal Complete_SS'] = pd.to_datetime(final_google['Tree Removal Complete_SS']).dt.date\n",
    "\n",
    "# final_google['Match Check'] = (final_google['Tree Removal Complete_GG'] == final_google['Tree Removal Complete_SS'])\n",
    "\n",
    "# final_google = final_google[final_google['Match Check'] == False]\n",
    "# final_google.to_excel('Check TREE removal complete date.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc6605",
   "metadata": {},
   "source": [
    "# Check for Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6032b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salmon = df_both.copy()\n",
    "# salmon = salmon[salmon['Salmon Habitat'].notna()][['APN_ROW Segment','Street #', 'Street Name', 'Structural Status','County', 'Tree Crew','Salmon Habitat']]\n",
    "# salmon['Salmon Habitat'] = np.where(salmon['Salmon Habitat'] == 1,'Has Salmon', \"\")\n",
    "# salmon.set_index('APN_ROW Segment', inplace=True)\n",
    "# salmon.to_excel('Check Salmon Habit.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d236791",
   "metadata": {},
   "source": [
    " # Temp signage checks - RTR vs smartsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d4cbc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #RTR data set up\n",
    "# sign = df_RTR.copy()\n",
    "# sign = sign[['Zone Name','Is Void', 'GIS Zone1', 'Service Code', 'Unit Count']]\n",
    "# sign = sign[(sign['Service Code'].isin([\"67A\"])) & ~(sign['GIS Zone1'].isin([division_rtr])) & (sign['Is Void']== False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "626565b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Smartsheets set up\n",
    "# sign_SS = df_both.copy()\n",
    "# sign_SS = sign_SS[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status', 'Debris Crew', 'Tree Crew',\n",
    "#                         '811 Called (A&M)']]\n",
    "# final_sign = sign_SS.merge(sign,\n",
    "#                           left_on='APN_ROW Segment',\n",
    "#                           right_on='Zone Name',\n",
    "#                           how='outer')\n",
    "# final_sign.to_excel('811 A&M Ticket checks RTR vs Smart Sheets.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc57fd",
   "metadata": {},
   "source": [
    "# Check for Abatment property statuses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a10044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "abatment = df_both.copy()\n",
    "abatment = abatment[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status','ROE Type', 'Debris Crew',\n",
    "                     'Tree Crew',\n",
    "            'Debris Start', 'Debris Finish', 'Soil Samples Approved', 'FSO Complete',\n",
    "                     'Haz Trees Present?', 'Tree Felling Start','Tree Removal Complete (ISW)', 'Tree FSW',\n",
    "                     'ROE Verified', 'ROE Date']]\n",
    "abatment['Abatment Expires'] = pd.to_datetime(abatment['ROE Date']).dt.date + timedelta(days=30)\n",
    "\n",
    "abatment.set_index('APN_ROW Segment',inplace=True)\n",
    "abatment = abatment[abatment['ROE Verified'] == 'Abatement'].to_excel('Abatment Checks.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "843f0b20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_both.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a071ed",
   "metadata": {},
   "source": [
    "# check holds and their status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ea017a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Holds = df_both.copy()\n",
    "Holds = Holds[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status','ROE Type',\n",
    "               'Debris Crew', 'Tree Crew',\n",
    "            'Debris Start', 'Debris Finish',\n",
    "               'Soil Samples Approved', 'FSO Complete', 'FSO Sent to County',\n",
    "                     'Tree FSW','Hold', 'Hold Reason',\n",
    "                     'ROE Verified']]\n",
    "\n",
    "Holds = Holds[Holds['Hold'] == True].to_excel(\"Holds checks.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e206eae5",
   "metadata": {},
   "source": [
    "# Check Bird Nests that are active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a0a7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = df_both.copy()\n",
    "birds = birds[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status',\n",
    "              'Nesting Bird Survey Date', 'Nesting Bird Survey Results', 'Hold']]\n",
    "birds = birds[(birds['Nesting Bird Survey Results'] == \"Active Nest\") & (birds['Hold'] != 1.0)]\n",
    "\n",
    "birds.set_index('APN_ROW Segment', inplace=True)\n",
    "birds.to_excel('Active Birds nest not on hold.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4f70e",
   "metadata": {},
   "source": [
    "# bridge/crossing checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c77c27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = df_both.copy()\n",
    "bridge = bridge[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status',\n",
    "                'OES EHP Attention Required',\n",
    "                 'Water crossing/bridge needed?', 'Water crossing/bridge install', 'Water crossing/bridge removal']]\n",
    "bridge = bridge[bridge['OES EHP Attention Required'].notna()]\n",
    "bridge.set_index('APN_ROW Segment', inplace=True)\n",
    "bridge.to_excel('Check for bridge updates.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efcfbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
