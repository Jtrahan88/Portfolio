{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6df511",
   "metadata": {},
   "source": [
    "# What databases need to be downloaded:\n",
    "* smartsheets - API is running no need\n",
    "* RTR - aDataManagerTicketExport \n",
    "* RTR URL: https://rtr.tdr.tetratech.com/rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f992a",
   "metadata": {},
   "source": [
    "# # What we are checking over view:\n",
    "\n",
    "#### Multiple checks\n",
    "* Soil data with share ppoint and Smart sheet comparasions(learning curve to read the out put)\n",
    "* Soil- Location in smart sheets\n",
    "* Soil -Sample date after recived from lab dates\n",
    "* Soil -Sample approval but debris status still in soils\n",
    "#### other checks\n",
    "* Soil sample prio to debris finish\n",
    "* ROE checks - ROE date is blank | ROE Verified is blank | Property Type is blank\n",
    "* FSO checks - FSO sent to county is not blank with ROE type full program and FSO debris complete is blank\n",
    "* ASB sample sent prior to ASB assessment\n",
    "* ASB results prior to ASB sample sent date\n",
    "* Debris start date is after debris finish date\n",
    "* Missing lat and long\n",
    "* Tree check - Checks for number of days from tree felling complete till ready for TISW\n",
    "* Salmon - obsolete\n",
    "* 811 A&M checks\n",
    "* Bird nests\n",
    "* Bridge CRossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7f5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import smartsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f92f39",
   "metadata": {},
   "source": [
    "Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79e737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileType_ex = \".xlsx\"\n",
    "fileType_csv = \".csv\"\n",
    "division = 'Northern Division' # will be opposite of the division we are checking. Help check for evrything NOT in Northern Division\n",
    "division_rtr = 'NORTHERN DIVISION'\n",
    "# grabs smartsheet data \n",
    "# central = r\"C:\\Users\\jacque.trahan\\Downloads\\Central Division 2021 Debris Removal Tracker*\" \n",
    "# south = r\"C:\\Users\\jacque.trahan\\Downloads\\South Central Division 2021 Debris Removal Tracker*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112dcaae",
   "metadata": {},
   "source": [
    "# Load in smartsheet using the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cc6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smartsheets Shet IDs\n",
    "Central_id = '1844440261257092'\n",
    "South_id= '6292262490531716'\n",
    "\n",
    "# Smart sheet APIs\n",
    "# Central's API\n",
    "Central = smartsheet.Smartsheet('6jJFxnAfFsDErU0BSr1Ae4D6cHq0zenczVR12') #API\n",
    "Central.errors_as_exceptions(True)# Make sure we don't miss any errors\n",
    "\n",
    "# Central's API\n",
    "South = smartsheet.Smartsheet(\"H8mqAo60J2zGHSrJEwmlMoY88A9yjgCo6RnSI\") # API\n",
    "South.errors_as_exceptions(True)# Make sure we don't miss any errors\n",
    "\n",
    "# load in Smartsheets to pandas data frame - A FUNCTION IS NEEDED\n",
    "# Function to read in column titles and row vales and make out data frames\n",
    "def smartsheet_loadup(sheet):\n",
    "    \"\"\"Runs through the smartsheets collection of values and create a Pandas data frame\"\"\"\n",
    "    columns = [col.title for col in sheet.columns]\n",
    "    rows = []\n",
    "    for row in sheet.rows:\n",
    "        cells = []\n",
    "        for cell in row.cells:\n",
    "            cells.append(cell.value)\n",
    "        rows.append(cells)\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    return df\n",
    "\n",
    "Central_SS = smartsheet_loadup(Central.Sheets.get_sheet(Central_id))\n",
    "South_SS = smartsheet_loadup(South.Sheets.get_sheet(South_id))\n",
    "\n",
    "df_both = pd.concat([Central_SS,South_SS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc338303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_both['County'].value_counts().index.to_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d9815",
   "metadata": {},
   "source": [
    "# Smart Sheets dowload upload from download folder and concate\n",
    "\n",
    "### made better above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487d7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Central\n",
    "# load = glob.glob(central+fileType_ex)\n",
    "# df = pd.read_excel(max(load, key=os.path.getctime), parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79357369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # South Central\n",
    "# load2 = glob.glob(south+fileType_ex)\n",
    "# df2 = pd.read_excel(max(load2, key=os.path.getctime), parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef43d18",
   "metadata": {},
   "source": [
    "#### Concate Central and South Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48a65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_both = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4270a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_both.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3454a",
   "metadata": {},
   "source": [
    "# Fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad95ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(df, comp1=None, comp2=None, comp3=None):\n",
    "    \"\"\"Compares columns in our dataframe\"\"\"\n",
    "    if comp3 == None:\n",
    "        if df[comp1] == df[comp2]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if df[comp1] == df[comp2] and df[comp2] == df[comp3]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "        \n",
    "        \n",
    "def greater(df, comp1=None, comp2=None):\n",
    "    \"\"\"Checks for dates greater than another\"\"\"\n",
    "    if df[comp1] > df[comp2]:\n",
    "        return \"Greater than\"\n",
    "    else:\n",
    "        return \"Less Than\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b547b79",
   "metadata": {},
   "source": [
    "# Soil Share Point Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "309c5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_soilTracker = r\"C:\\Users\\jacque.trahan\\Downloads\\Soil Sampling Tracker*\"\n",
    "load_soil = glob.glob(path_soilTracker + fileType_csv)\n",
    "soils_sharePoint = pd.read_csv(max(load_soil, key=os.path.getctime), usecols=['APN', 'APN Status', 'Field Notes', 'Tt Recommendation', 'Date Collected',\n",
    "                                                                              \"Date Lab Recd\",\n",
    "                                                                       'State Recommendation', 'State Rec Details',\n",
    "                                                                        'DTSC Mercury Site','State Recommendation',\n",
    "                                                                      'State Rec Details','State Rec Date','QC State Recs','ExpectedResultsDate',\n",
    "                                                                      'Current Sample Event','Division', 'Recs Notes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926e8c5d",
   "metadata": {},
   "source": [
    "# No sample date in SS, But sampled in Soil tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "549e169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soils_sharePoint = soils_sharePoint[(~soils_sharePoint['Division'].isin(['Northern Division']))]\n",
    "\n",
    "Soil_Sample_date_checks = df_both.merge(soils_sharePoint,\n",
    "                                       left_on='APN_ROW Segment',\n",
    "                                       right_on='APN',\n",
    "                                       how='outer')\n",
    "\n",
    "Soil_Sample_date_checks = Soil_Sample_date_checks[['APN_ROW Segment','Street #', 'Street Name', 'County', 'Structural Status', 'Debris Crew',\n",
    "        'APN Status', 'Soil Sample','Date Collected']].copy()\n",
    "\n",
    "\n",
    "Soil_Sample_date_checks = Soil_Sample_date_checks[(Soil_Sample_date_checks['Soil Sample'].isnull())\n",
    "                                                  & (Soil_Sample_date_checks['Date Collected'].notnull())]\n",
    "\n",
    "Soil_Sample_date_checks.set_index('APN_ROW Segment', inplace=True)\n",
    "Soil_Sample_date_checks.to_excel('No Soil Sample Dates in smartsheets.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b922f",
   "metadata": {},
   "source": [
    "# RTR data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d054937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Replace_APNs = {'167-310-2500':'167-310-25-00','028-370-004 21285': '028-370-004_21285',\n",
    "                '028-370-004 21275':'028-370-004_21275'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423627da",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\jacque.trahan\\Downloads\\aDataManagerTicketExport*\"\n",
    "load_rtr = glob.glob(path+fileType_ex)\n",
    "df_RTR = pd.read_excel(max(load_rtr, key=os.path.getctime))\n",
    "\n",
    "df_RTR['Zone Name'] = df_RTR['Zone Name'].str.replace(\"-\",\"\")\n",
    "df_RTR['Zone Name'] = df_RTR['Zone Name'].str.strip()\n",
    "df_RTR['Zone Name'] = df_RTR['Zone Name'].str[:3] + \"-\" + df_RTR['Zone Name'].str[3:6] + \"-\" + df_RTR['Zone Name'].str[6:]\n",
    "\n",
    "df_RTR= df_RTR.replace({'Zone Name': Replace_APNs})\n",
    "df_RTR['Service Code'] = df_RTR['Service Code'].str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf173c",
   "metadata": {},
   "source": [
    "# Check APN mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c8a08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APN_check = df_RTR.copy()\n",
    "# APN_check_final = APN_check.merge(df_both,\n",
    "#                                  left_on='Zone Name',\n",
    "#                                  right_on='APN_ROW Segment',\n",
    "#                                  how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e99c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APN_check_final = APN_check_final[(APN_check_final['APN_ROW Segment'] != APN_check_final['Zone Name']) &\n",
    "#                (APN_check_final['GIS Zone1'].isin(['CENTRAL DIVISION']))]\n",
    "\n",
    "# APN_check_final = APN_check_final[['APN_ROW Segment', 'Zone Name',\n",
    "#                                    'GIS Zone1','GIS Zone2']].to_excel('Check APNs in RTR VS SS.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16ebca",
   "metadata": {},
   "source": [
    "# Check ROE dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a1f317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROE_dates = df_both[['APN_ROW Segment','Street #', 'Street Name', 'County','Debris Crew', 'Structural Status',\n",
    "                         'ROE Date', 'ROE Verified',\n",
    "                    'Property Type', ]]\n",
    "ROE_dates = ROE_dates[(ROE_dates['ROE Date'].isnull()) | \n",
    "                     (ROE_dates['ROE Verified'].isnull()) | \n",
    "                    (ROE_dates['Property Type'].isnull())]\n",
    "\n",
    "ROE_dates.set_index('APN_ROW Segment', inplace=True)\n",
    "ROE_dates.to_excel('ROE Random Checks.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f928d2f",
   "metadata": {},
   "source": [
    "# FSO Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "815d1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FSO = df_both.copy()\n",
    "\n",
    "FSO = FSO[(~FSO['FSO Sent to County'].isnull()) & (FSO['ROE Type'] == \"Full Program ROE (debris + trees)\") &\n",
    "          (FSO['Debris FSO Complete'].isnull())]\n",
    "\n",
    "FSO = FSO[['APN_ROW Segment','Street #', 'Street Name', 'County', 'Structural Status','ROE Type',\n",
    "           'Erosion Control Complete', 'Erosion Control Waiver',\n",
    "          'Debris FSO Complete', 'FSO Complete', 'FSO Sent to County']]\n",
    "\n",
    "FSO.set_index('APN_ROW Segment', inplace=True)\n",
    "FSO.to_excel('FSO Check.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e596e0b",
   "metadata": {},
   "source": [
    "# ASB sample sent prior to ASB assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e892c5e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asb_sample = df_both.copy()\n",
    "asb_sample = asb_sample[['APN_ROW Segment','Street #', 'Street Name', 'County',\n",
    "                         'ASB Assessment', 'ASB Sample Sent']]\n",
    "asb_sample = asb_sample[(asb_sample['ASB Assessment'] > asb_sample['ASB Sample Sent'])]\n",
    "\n",
    "asb_sample.set_index('APN_ROW Segment', inplace=True)\n",
    "asb_sample.to_excel('ASB sample sent prior to ASB assessment.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52b963",
   "metadata": {},
   "source": [
    "# ASB results prior to ASB sample sent date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc6b7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "asb_res = df_both.copy()\n",
    "asb_res = asb_res[['APN_ROW Segment','Street #', 'Street Name', 'County',\n",
    "                   'ASB Sample Sent','ASB Results Received', 'ASB Results']]\n",
    "asb_res = asb_res[(asb_res['ASB Sample Sent'].isna()) & (asb_res['ASB Results'].notna())]\n",
    "\n",
    "asb_res.set_index('APN_ROW Segment', inplace=True)\n",
    "asb_res.to_excel('ASB results prior to ASB sample sent date.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd914d",
   "metadata": {},
   "source": [
    "# Check for Abatment property statuses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44077aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "abatment = df_both.copy()\n",
    "abatment = abatment[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status','ROE Type', 'Debris Crew',\n",
    "                     'Tree Crew',\n",
    "            'Debris Start', 'Debris Finish', 'Soil Samples Approved', 'FSO Complete',\n",
    "                     'Haz Trees Present?', 'Tree Felling Start','Tree Removal Complete (ISW)', 'Tree FSW',\n",
    "                     'ROE Verified', 'ROE Date']]\n",
    "\n",
    "abatment['Abatment Expires'] = pd.to_datetime(abatment['ROE Date']).dt.date + timedelta(days=30)\n",
    "abatment['Days Left'] = pd.to_datetime('today').date() - pd.to_datetime(abatment['Abatment Expires']).dt.date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c25802ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "abatment.set_index('APN_ROW Segment',inplace=True)\n",
    "abatment = abatment[(abatment['ROE Verified'] == 'Abatement') & (~abatment['Structural Status'].isin(['Ineligible']))\n",
    "                    & (abatment['FSO Complete'].isnull())].to_excel('Abatment Checks.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8f322",
   "metadata": {},
   "source": [
    "# Debris start after to debris finish\n",
    "### Check Debris dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18dc99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Debris_dates = df_both.copy()\n",
    "Debris_dates = Debris_dates[['APN_ROW Segment','Street #', 'Street Name', 'County',\n",
    "                          'Debris Start', 'Debris Finish', 'State Rep Sign-Off for DR']]\n",
    "\n",
    "Debris_dates['Debris Start-new'] = pd.to_datetime(Debris_dates['Debris Start'])\n",
    "Debris_dates['Debris Finish-new'] = pd.to_datetime(Debris_dates['Debris Finish'])\n",
    "\n",
    "Debris_dates.insert(Debris_dates.columns.get_loc('State Rep Sign-Off for DR')+1, \"Finish start before Debris end\",\n",
    "                   Debris_dates.apply(greater,comp1='Debris Start-new', comp2='Debris Finish-new', axis=1))\n",
    "\n",
    "\n",
    "Debris_dates['Debris Start'] = pd.to_datetime(Debris_dates['Debris Start']).dt.date.fillna(0)\n",
    "Debris_dates['Debris Finish'] = pd.to_datetime(Debris_dates['Debris Finish']).dt.date.fillna(0)\n",
    "Debris_dates['State Rep Sign-Off for DR'] = pd.to_datetime(Debris_dates['State Rep Sign-Off for DR']).dt.date.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "Debris_dates.insert(Debris_dates.columns.get_loc('Finish start before Debris end')+1, 'Match debris end and state rep',\n",
    "                   Debris_dates.apply(compare, comp1='Debris Finish', comp2='State Rep Sign-Off for DR', axis=1))\n",
    "\n",
    "\n",
    "Debris_dates = Debris_dates[['APN_ROW Segment','Street #', 'Street Name', 'County',\n",
    "                          'Debris Start', 'Debris Finish', 'State Rep Sign-Off for DR',\"Finish start before Debris end\",  'Match debris end and state rep']]\n",
    "\n",
    "Debris_dates.set_index('APN_ROW Segment', inplace=True)\n",
    "Debris_dates.to_excel('Check debris start finish and state sign off dates.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f8621",
   "metadata": {},
   "source": [
    "# Soil Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f2c89",
   "metadata": {},
   "source": [
    "## Soil sample prior to debris finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1084d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_debris = df_both.copy()\n",
    "soil_debris = soil_debris[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status',\n",
    "                           'Soil Sample', 'Debris Finish']]\n",
    "\n",
    "soil_debris = soil_debris[(soil_debris['Soil Sample'] < soil_debris['Debris Finish'])]\n",
    "\n",
    "soil_debris.set_index('APN_ROW Segment', inplace=True)\n",
    "soil_debris.to_excel(\"Soil prior to debris Finish.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a23d5",
   "metadata": {},
   "source": [
    "# long and lats missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e7b719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lat = df_both.copy()\n",
    "lon_lat = lon_lat[['APN_ROW Segment','Street #', 'Street Name', 'County','Latitude', 'Longitude']]\n",
    "\n",
    "lon_lat = lon_lat[lon_lat['Latitude'].isna() | lon_lat['Longitude'].isna()]\n",
    "\n",
    "lon_lat.set_index('APN_ROW Segment', inplace=True)\n",
    "lon_lat.to_excel(\"Missing long and lat.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724de5b",
   "metadata": {},
   "source": [
    "# Check Tree removal and TISW dates\n",
    "https://docs.google.com/spreadsheets/d/1wF0GLNJG0dKTnkT0fEuC-kAIU4pzrr_IyhLnJ5iEZ7s/edit#gid=1185136840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "394c1eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planning_sheet_id = '1wF0GLNJG0dKTnkT0fEuC-kAIU4pzrr_IyhLnJ5iEZ7s'\n",
    "# Planning_sheet_name = '1185136840'\n",
    "\n",
    "# #gid # in URL lets you pick the sheet you want. Will need to look for that.\n",
    "# url_planning = f\"https://docs.google.com/spreadsheets/d/{Planning_sheet_id}/export?gid={Planning_sheet_name}&format=csv\"\n",
    "# planning_google = pd.read_csv(url_planning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae54996",
   "metadata": {},
   "source": [
    "# Check all dates are there for Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11b4db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree_date_checks = df_both.copy()\n",
    "\n",
    "Tree_date_checks = Tree_date_checks[(Tree_date_checks['Tree Felling Complete'].isnull() |\n",
    "                                     Tree_date_checks['Tree Removal Complete (ISW)'].isnull()) \n",
    "                                    & (Tree_date_checks['Tree FSW'].notnull())]\n",
    "\n",
    "Tree_date_checks = Tree_date_checks[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status',\n",
    "                                    'Tree Felling Complete','Tree Removal Complete (ISW)','Tree FSW']]\n",
    "Tree_date_checks.set_index('APN_ROW Segment', inplace=True)\n",
    "Tree_date_checks.to_excel('Check Tree missing dates.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a071ed",
   "metadata": {},
   "source": [
    "# check holds and their status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ea017a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Holds = df_both.copy()\n",
    "Holds = Holds[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status','ROE Type',\n",
    "               'Debris Crew', 'Tree Crew',\n",
    "            'Debris Start', 'Debris Finish',\n",
    "               'Soil Samples Approved', 'FSO Complete', 'FSO Sent to County',\n",
    "                     'Tree FSW','Hold', 'Hold Reason',\n",
    "                     'ROE Verified']]\n",
    "\n",
    "Holds = Holds[Holds['Hold'] == True].to_excel(\"Holds checks.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e206eae5",
   "metadata": {},
   "source": [
    "# Check Bird Nests that are active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a0a7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = df_both.copy()\n",
    "birds = birds[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status',\n",
    "              'Nesting Bird Survey Date', 'Nesting Bird Survey Results', 'Hold']]\n",
    "birds = birds[(birds['Nesting Bird Survey Results'] == \"Active Nest\") & (birds['Hold'] != 1.0) &\n",
    "             (~birds['Structural Status'].isin(['Returned to County', 'Ready for Final Sign-off', 'Ready for Erosion Control']))]\n",
    "\n",
    "birds.set_index('APN_ROW Segment', inplace=True)\n",
    "birds.to_excel('Active Birds nest not on hold.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4f70e",
   "metadata": {},
   "source": [
    "# bridge/crossing checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c77c27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = df_both.copy()\n",
    "bridge = bridge[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status',\n",
    "                'OES EHP Attention Required',\n",
    "                 'Water crossing/bridge needed?', 'Water crossing/bridge install', 'Water crossing/bridge removal']]\n",
    "\n",
    "bridge = bridge[bridge['OES EHP Attention Required'].notna()]\n",
    "bridge.set_index('APN_ROW Segment', inplace=True)\n",
    "bridge.to_excel('Check for bridge updates.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf0711d",
   "metadata": {},
   "source": [
    "# Check pending vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ad8819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = df_both.copy()\n",
    "vecs = vecs[['APN_ROW Segment','Street #', 'Street Name', 'County','Structural Status', 'Debris Crew',\n",
    "            'Vehicle Removal Complete']]\n",
    "# conditions\n",
    "vecs = vecs[(vecs['Debris Crew'] == 'FSO Pending Vehicles')]\n",
    "vecs.to_excel('Check FSO pending vecs and if vecs were removed.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aae32e",
   "metadata": {},
   "source": [
    "# Make sure Fire Names are not missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "908c5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_name = df_both[['APN_ROW Segment','Street #', 'Street Name', 'County','Fire Name']]\n",
    "fire_name = fire_name[fire_name['Fire Name'].isnull()]\n",
    "fire_name.to_excel('Firenames.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678bd455",
   "metadata": {},
   "source": [
    "# Checks for missing Special Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "183741c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = df_both[(df_both['ROE Type'] == 'Full Program ROE (debris + trees)') & \n",
    "               (df_both['Debris Finish'].notnull())]\n",
    "\n",
    "notes = notes[['APN_ROW Segment','Street #', 'Street Name', 'County', 'ROE Type', 'Structural Status',\n",
    "                          'Debris Start', 'Debris Finish', 'State Rep Sign-Off for DR', 'Special Notes']]\n",
    "notes.to_excel('get missing Special notes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abba474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
